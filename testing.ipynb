{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing running on ECOO with mlm model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sacharfd/miniconda3/envs/ecco/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  2.76it/s]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  2.78it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModel, AutoModelForSeq2SeqLM\n",
    "import ecco\n",
    "hf_model_id = 'google/gemma-2b-it'\n",
    "# hf_model_id = 'gpt2'\n",
    "\n",
    "# ecco_model = ecco.from_pretrained(hf_model_id, verbose=True, gpu=1)\n",
    "\n",
    "# 1- load the model the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(hf_model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(hf_model_id)\n",
    "\n",
    "model_config = {\n",
    "    'embedding': \"model.embed_tokens\",\n",
    "    'type': 'mlm',\n",
    "    'activations': ['mlp\\.up_proj'], #This is a regex\n",
    "    'token_prefix': '',\n",
    "    'partial_token_prefix': ''\n",
    "}\n",
    "\n",
    "ecco_model = ecco.from_pretrained(hf_model_id, \n",
    "                                  activations=True,\n",
    "                                  model_config=model_config,\n",
    "                                  gpu=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat = [\n",
    "#    {\"role\": \"user\", \"content\": \"You are a materials chemistry expert and your role is to answer questions about high-entropy alloys. You will be asked to classify the phase of the alloy based on its composition. Answer either 'single-phase' or 'multi-phase'. Do not provide any additional information.\\n\\nWhat is the phase of Co1Cu1Fe1Ni1V1?\\n\\n\"},\n",
    "# ]\n",
    "# example_to_generate = tokenizer.apply_chat_template(chat, tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html lang=\"en\">\n",
       "<script src=\"https://requirejs.org/docs/release/2.3.6/minified/require.js\"></script>\n",
       "<script>\n",
       "    var ecco_url = 'https://storage.googleapis.com/ml-intro/ecco/'\n",
       "    //var ecco_url = 'http://localhost:8000/'\n",
       "\n",
       "    if (window.ecco === undefined) window.ecco = {}\n",
       "\n",
       "    // Setup the paths of the script we'll be using\n",
       "    requirejs.config({\n",
       "        urlArgs: \"bust=\" + (new Date()).getTime(),\n",
       "        nodeRequire: require,\n",
       "        paths: {\n",
       "            d3: \"https://d3js.org/d3.v6.min\", // This is only for use in setup.html and basic.html\n",
       "            \"d3-array\": \"https://d3js.org/d3-array.v2.min\",\n",
       "            jquery: \"https://code.jquery.com/jquery-3.5.1.min\",\n",
       "            ecco: ecco_url + 'js/0.0.6/ecco-bundle.min',\n",
       "            xregexp: 'https://cdnjs.cloudflare.com/ajax/libs/xregexp/3.2.0/xregexp-all.min'\n",
       "        }\n",
       "    });\n",
       "\n",
       "    // Add the css file\n",
       "    //requirejs(['d3'],\n",
       "    //    function (d3) {\n",
       "    //        d3.select('#css').attr('href', ecco_url + 'html/styles.css')\n",
       "    //    })\n",
       "\n",
       "    console.log('Ecco initialize!!')\n",
       "\n",
       "    // returns a 'basic' object. basic.init() selects the html div we'll be\n",
       "    // rendering the html into, adds styles.css to the document.\n",
       "    define('basic', ['d3'],\n",
       "        function (d3) {\n",
       "            return {\n",
       "                init: function (viz_id = null) {\n",
       "                    if (viz_id == null) {\n",
       "                        viz_id = \"viz_\" + Math.round(Math.random() * 10000000)\n",
       "                    }\n",
       "                    // Select the div rendered below, change its id\n",
       "                    const div = d3.select('#basic').attr('id', viz_id),\n",
       "                        div_parent = d3.select('#' + viz_id).node().parentNode\n",
       "\n",
       "                    // Link to CSS file\n",
       "                    d3.select(div_parent).insert('link')\n",
       "                        .attr('rel', 'stylesheet')\n",
       "                        .attr('type', 'text/css')\n",
       "                        .attr('href', ecco_url + 'html/0.0.2/styles.css')\n",
       "\n",
       "                    return viz_id\n",
       "                }\n",
       "            }\n",
       "        }, function (err) {\n",
       "            console.log(err);\n",
       "        }\n",
       "    )\n",
       "</script>\n",
       "\n",
       "<head>\n",
       "    <link id='css' rel=\"stylesheet\" type=\"text/css\">\n",
       "</head>\n",
       "<div id=\"basic\"></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n         requirejs( ['basic', 'ecco'], function(basic, ecco){\n            basic.init('viz_465412') // Python needs to know the viz id. Used for each output token.\n            window.ecco['viz_465412'] = new ecco.renderOutputSequence({\n                    parentDiv: 'viz_465412',\n                    data: {\"tokens\": [{\"token\": \"<bos>\", \"is_partial\": true, \"position\": 0, \"token_id\": 2, \"type\": \"input\"}, {\"token\": \"Hello\", \"is_partial\": true, \"position\": 1, \"token_id\": 4521, \"type\": \"input\"}, {\"token\": \"how\", \"is_partial\": true, \"position\": 2, \"token_id\": 1368, \"type\": \"input\"}, {\"token\": \"are\", \"is_partial\": true, \"position\": 3, \"token_id\": 708, \"type\": \"input\"}, {\"token\": \"you\", \"is_partial\": true, \"position\": 4, \"token_id\": 692, \"type\": \"input\"}, {\"token\": \"\", \"is_partial\": true, \"position\": 5, \"token_id\": 235248, \"type\": \"input\"}]},\n                    tokenization_config: {\"token_prefix\": \"\", \"partial_token_prefix\": \"\"}\n            \n            })\n         }, function (err) {\n            console.log(err);\n        })\n        ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n        // We don't really need these require scripts. But this is to avert\n        //this code from running before display_input_sequence which DOES require external files\n        requirejs(['basic', 'ecco'], function(basic, ecco){\n                console.log('addToken viz_id', 'viz_465412');\n                window.ecco['viz_465412'].addToken({\"token\": \"\\n\\n\", \"is_partial\": true, \"token_id\": 109, \"position\": 6, \"type\": \"output\"})\n                window.ecco['viz_465412'].redraw()\n        })\n        ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AssertionError",
     "evalue": "method not supported for Masked-LMs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Create the prompt using tokenizer: \u001b[39;00m\n\u001b[1;32m      4\u001b[0m output_1 \u001b[38;5;241m=\u001b[39m ecco_model\u001b[38;5;241m.\u001b[39mgenerate(example_to_generate, generate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, do_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, output_hidden_states\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 5\u001b[0m \u001b[43moutput_1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrankings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# output_1.rankings_watch(watch=[582, 2415], position=1)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# output_1.__dict__.keys()\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ecco/lib/python3.8/site-packages/ecco/output.py:442\u001b[0m, in \u001b[0;36mOutputSeq.rankings\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrankings\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    435\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;124;03m    Plots the rankings (across layers) of the tokens the model selected.\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;124;03m    Each column is a position in the sequence. Each row is a layer.\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \n\u001b[1;32m    439\u001b[0m \u001b[38;5;124;03m    ![Rankings watch](../../img/rankings_ex_eu_1.png)\u001b[39;00m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 442\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmlm\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmethod not supported for Masked-LMs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    444\u001b[0m     _, dec_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_hidden_states()\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m dec_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder hidden states not found\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: method not supported for Masked-LMs"
     ]
    }
   ],
   "source": [
    "example_to_generate = \"Hello how are you \"\n",
    "\n",
    "# Create the prompt using tokenizer: \n",
    "output_1 = ecco_model.generate(example_to_generate, generate=1, do_sample=False, output_hidden_states=True)\n",
    "output_1.rankings()\n",
    "# output_1.rankings_watch(watch=[582, 2415], position=1)\n",
    "# output_1.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<bos>Hello how are you \\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_1.n_input_tokens\n",
    "output_1.output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_to_generate = \"You are a materials chemistry expert and your role is to answer questions about high-entropy alloys. You will be asked to classify the phase of the alloy based on its composition. Answer either 'single-phase' or 'multi-phase' ONLY. Do not provide any additional information.\\nWhat is the phase of Co1Cu1Fe1Ni1V1?\\n\\n\"\n",
    "\n",
    "# # Create the prompt using tokenizer: \n",
    "# output_1 = ecco_model.generate(example_to_generate, generate=20, do_sample=False, output_hidden_states=True)\n",
    "# output_1.rankings()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
